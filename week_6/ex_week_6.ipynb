{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #00695C; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "# Week 6 - Catch-up from week 5 and filtering\n",
    "\n",
    "This week will be a mixture of exercises from last time (So feel free to skip those if you already did them, and a few new ones, focusing on filtering). Last week, we forgot to add learning objectives, so they'll be added here for both week 5 and week 6\n",
    "\n",
    "**At the end of this week 5, you should be able to:**\n",
    "\n",
    "- Understand what the fourier coefficients of a signal mean for the signal's amplitudes and frequencies\n",
    "- Know how to calculate fourier coefficients of a sampled signal using a series\n",
    "- Know how to calculate the actual frequencies that the fourier coefficients correspond to\n",
    "- Know how to calculate the energy of a signal, or of a a specific frequency in a signal\n",
    "- Know what freuqency bins are, and how to ensure that the frequencies captured by the fourier transformation will be ones relevant for the signal itself\n",
    "- Know and explain that the fourier coefficient is linear\n",
    "- Know roughly how to perform the fourier transform using Python packages\n",
    "- Know how the frequency domain can be used to recognize noisy parts of a signal\n",
    "- Know how different kinds of noise (white noise, talking noise, fan noise, etc.) can show itself in different ways in both the time- and frequency domains\n",
    "\n",
    "**Optional**:\n",
    "- Know what the short time fourier transform is, and why it is useful for analyzing sound\n",
    "- Know what the \"power\" of noise corresponds to\n",
    "- Know something about how different waves on the same frequencies can can interfere with one another, for example in telecommunications\n",
    "\n",
    "**At the end of week 6, you should be able to**\n",
    "\n",
    "- Know how convolution is important for discrete filtering of signals\n",
    "- Know how to apply a discrete filter to a signal in the **time domain**\n",
    "- Know how to apply a discrete filter to a signal in the **frequency domain**\n",
    "- Explain what the impulse respones of a filter is\n",
    "- Know why it can be relevant to look at a filter's impulse response in both the time domain *and* the frequency domain\n",
    "- Explain the difference between a low-pass, a band-pass, and a high-pass filter\n",
    "- Explain the intuitive effect of applying a filter, like a low-pass filter to a human speaking\n",
    "\n",
    "**Optional**\n",
    "- Implement functions to apply filtering in the time domain\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Filtering of sinusoidals is fairly straightforward. It is defined a the **convolution** of a filter (Usually denoted $h(n)$) and a time signal $x(n)$. Now you may say:\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "  <em>\"But wait, we already know about convolution using images and kernels?\"</em>\n",
    "</div>\n",
    "\n",
    "Right you are, Harry! There is **next to no difference** from the convolution of images vs the convolution of signals. Where in convolution of images (usually called 2d convolution), you 'slide' a **kernel** across the image and calculate values like so. In signal convolution (usually called 1d convolution), you 'slide' a **filter** across the signal and calculate values. For a continuous signal, this looks like so **(Notice the filter has been flipped as to perform convolution and not cross-correlation)**:\n",
    "\n",
    "<img src=\"images/Convolution.gif\" \n",
    "        style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "That was for a **continuous example**, in our case, we will concern our selves with the **discrete case**:\n",
    "\n",
    "<img src=\"images/Discrete_convolution_1.gif\" \n",
    "        style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "In both cases, plot of the filter (noted as \"Impulse response\" in continuous case, and \"Kernel\" in the discrete response), is what's called the **impulse response** of the filter. \n",
    "\n",
    "Explanations of this usually involve fancy maths about delta functions and whatever, but basically it is **the output you get if you pass the filter over a function that consists of a single value** (called a delta, or Dirac delta function):\n",
    "\n",
    "<img src=\"images/delta_function_jpeg.jpg\"\n",
    "        alt='The Mighty Delta Function'\n",
    "        width = 400\n",
    "        height = 300\n",
    "        style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "You can think this **impulse response** as the \"shape\" of the filter, in the sense that you see how each new value is calculated. In an actual signal, there would also be surrounding signal values to permute this result, of course.\n",
    "\n",
    "As for the actual formula for convolution of signal, it is defined both for discrete and continuous signals (we will only use the discrete case in this course):\n",
    "\n",
    "$$y(k) = x(n) * h(n) = \\sum^{\\infty}_{n=-\\infty} x(n) h(k - n)$$\n",
    "\n",
    "$$y(t) =  x(t) * h(t) = \\int^\\infty{-\\infty} x(t) h(t - \\tau) d\\tau$$\n",
    "\n",
    "---\n",
    "\n",
    "## Filtering in the frequency domain\n",
    "\n",
    "First of, we can mention: **you can take the fourier transform of a filter, just as you would a time signal**. Next, probably mentioned before, but one nice property of the fourier transform, is that **convolutions in the time domain become multiplications in the frequency domain**.\n",
    "\n",
    "And that's pretty much all there is to it... This is really cool since convolution is a rather slow operation, and fourier transforms are not (thanks to the Fast Fourier Transform (FFT (a fast algorithm for getting a fourier transform not covered in this course))). That means, it is sometimes faster to take the FFT of a signal, multiply it with a filter, and take the inverse FFT, than it is to simply convolve the time domain version of the singal with the time domain filter.\n",
    "\n",
    "**Another useful feature:** is that if you plot a filter in the frequency domain, it's impulse response will just show directly which frequencies will be attenuated or amplified, almost as a regular fourier transform plot would. An example we will see later plotted below:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "  <img src=\"images/impulse_response.png\" alt=\"Impulse response of filter\" width=\"300\"/>\n",
    "  <img src=\"images/frequency_domain.png\" alt=\"Same filter fourier transformed\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "Here, to the right is the impulse response, which tells us something about how a single value will be affected **in the time domain** - this isn't really all that useful. However, to the left we can see how the **amplitude of each frequency of a signal** will be affected? That's useful!.\n",
    "\n",
    "---\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As in week 4, if you encounter problems playing audio, use this workaround with Sounddevice instead...\n",
    "import sounddevice as sd\n",
    "\n",
    "def play_sine_wave_sounddevice(time_signal, sample_rate=44100):\n",
    "    \"\"\"\n",
    "    Play a sine wave generated as as um of given frequencies, amplitudes and phases for a given duration with a givne sample rate\n",
    "\n",
    "    Args:\n",
    "        frequencies (list[int]): List of frequencies in the signal\n",
    "        amplitudes (list[int]): List of amplitudes of each distinct frequency in the signal\n",
    "        phases (list[int]): List of phases in the signal (in radians)\n",
    "        duration (int): How long to play the sound\n",
    "        sample_rate (int, optional): F_s, sample rate to digitally sample the signal, might remove frequencies if too low. Defaults to 44100.\n",
    "    \"\"\"\n",
    "    # Generate sine wave\n",
    "    sd.play(time_signal, samplerate=sample_rate)\n",
    "    sd.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 1 - Fourier Transform manual calculation\n",
    "\n",
    "You are given the following discrete signal values, sampled over a duration of $2$ seconds with a sample rate $f_s = 4$\n",
    "\n",
    "$$x(n) = [ 0,  1.21, -1,  0.21, 0, -0.21, 1, -1.21]$$\n",
    "\n",
    "#### **1.1. What is the maximum frequency the fourier transform will be able to represent?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **1.2. What are the specific *frequency bins*, meaning for any $X(k)$ (output from the fourier transform) what specific frequency will that fourier coeffcient correspond to for this specific case?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **1.3. Look at the below calculation for the fourier coefficient corresponding to $k = 2$, and convince yourself that it makes sense**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Here we just use the formula above with the associated values, it is a bit of work though\n",
    "\n",
    "$$X(2) = (0\\cdot\\exp(\\frac{-(2\\cdot 2\\cdot i\\cdot \\pi)\\cdot0}{8})) + 1.21\\cdot\\exp\\frac{(-(2\\cdot2\\cdot i\\cdot \\pi)}{8}) - 1\\cdot\\exp(\\frac{-(2\\cdot2\\cdot i\\cdot \\pi)\\cdot2}{8}) + 0.21\\cdot\\exp(\\frac{-(2\\cdot2\\cdot i\\cdot \\pi)\\cdot 3}{8}) + 0\\cdot\\exp(\\frac{-(2\\cdot2\\cdot i\\cdot \\pi)\\cdot 4}{8}) - 0.21\\cdot\\exp(\\frac{-(2\\cdot2\\cdot i\\cdot pi)\\cdot5}{8}) + 1\\cdot\\exp(\\frac{-(2\\cdot 2\\cdot i \\cdot \\pi)\\cdot6}{8}) - 1.21\\cdot\\exp(\\frac{-(2\\cdot2\\cdot i \\cdot \\pi)\\cdot 7}{8}))$$\n",
    "\n",
    "$$ = 2$$\n",
    "\n",
    "Which when we then normalize by the amount of samples gives us\n",
    "\n",
    "$$X(2) = \\frac{2}{8} = 0.25$$\n",
    "\n",
    "And since we need to overlay positive and negative frequencies, we multiply by two:\n",
    "\n",
    "$$0.25 \\cdot 2  = 0.5$$\n",
    "\n",
    "So we can say that the amplitude associated with the frequency $f_k =  \\frac{k}{N} \\cdot f_s = \\frac{2}{8} \\cdot 4 = 1$ is $0.5$ \n",
    "\n",
    "COPY this into maple if you just wanna see it there\n",
    "\n",
    "bs(0*exp(-(2*2*I*Pi)*0/8) + 1.21*exp(-(2*2*I*Pi)/8) - exp(-(2*2*I*Pi)*2/8) + 0.21*exp(-(2*2*I*Pi)*3/8) + 0*exp(-(2*2*I*Pi)*4/8) - 0.21*exp(-(2*2*I*Pi)*5/8) + exp(-(2*2*I*Pi)*6/8) - 1.21*exp(-(2*2*I*Pi)*7/8))\n",
    "\n",
    "Though you should really be using Python for this\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "# import sounddevice as sd # Needed to play sounds - Only use if IPython.display.Audio does not work\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.fft import fft, fftfreq, ifft # Technically used here is the fast fourier transform because it is... fast, don't convern yourself with this\n",
    "from scipy.signal import butter, filtfilt, convolve, stft\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration):\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "    wave = sum([amplitudes[i] * np.sin(2 * np.pi * frequencies[i] * t + phases[i]) for i in range(len(frequencies))])\n",
    "    return wave\n",
    "\n",
    "def calculate_fourier_coeffcients(signal_values, sample_rate=1, v=True):\n",
    "    N = len(signal_values)\n",
    "    coeffs = []\n",
    "\n",
    "    # Calculate fourier coefficient for each frequency bin\n",
    "    for k in range(N):\n",
    "        # Create values to sum in order to obtain fourier coefficients\n",
    "        prepared_to_sum = [... for n, x_n in enumerate(signal_values)] # Multiply each signal value by the complex exponential (DFT formula)\n",
    "\n",
    "        coeffs.append(sum(prepared_to_sum) / N) # Divide by N to normalize frequency values\n",
    "        \n",
    "        # Print results to the terminal\n",
    "        if v:\n",
    "            frequency = ...\n",
    "            absolute_coefficient = ... # Get absolute value to remove imaginary parts\n",
    "            print(f\"The fourier coeffcient associated with frequency {frequency:.3f}: {absolute_coefficient:3f}\")\n",
    "            if k == N / 2:\n",
    "                print(\"############ Frequencies Loop ############\")\n",
    "\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 2 - Calculating fourier coeffients with Python\n",
    "\n",
    "Far easier it is to create Python functions that calculate the fourier coeffcients for us.\n",
    "\n",
    "For each exercise, you can test your implementation in the cell below\n",
    "\n",
    "#### **2.1. ðŸ’» The first of the above two functions generate a sine wave based on a series on input amplitudes, phases, frequencies, sample rates and a duration of the signal. The second should calculate the fourier coefficients of said sine wave. Complete the function to calculate the fourier coefficients.**\n",
    "\n",
    "\n",
    "#### **2.2. ðŸ’» Change the values of the sample rate or frequency to see if you can make a signal whose frequencies cannot be accurately represented by the fourier transform**\n",
    "\n",
    "#### **2.3. What do you think happens with the fourier coefficients when the signal contains a frequency that does not correspond to any of the frequency bins?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [0.5, 2]\n",
    "amplitudes = [0.5, 1]\n",
    "phases = [0, 0]\n",
    "\n",
    "sample_rate = ...\n",
    "duration = ...\n",
    "\n",
    "signal_values = generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration)\n",
    "coeffs = calculate_fourier_coeffcients(signal_values, sample_rate=sample_rate, v=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "### Exercise 3 - Spectral Leakage\n",
    "\n",
    "In practice, simply being above the nyquist rate isn't everything you need to get the lower frequencies. The amount of samples also has an effect.\n",
    "\n",
    "In the code block below, we generate a signal with two frequencies: $F_1 = 0.25$ and $F_2 = 2$. We sample the signal with a sampling rate of $F_s = 5$ for a total of $\\mathbf{1}$ **second**.\n",
    "\n",
    "After that, we try to recover the fourier coefficients of the sampled signal.\n",
    "\n",
    "#### **3.1. In the code below, we are not able to recover the coefficient related to the frequency $F_1 = 0.25$, instead getting all kinds of coefficients with frequencies not in the signal, why is this?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **3.2. How can you change the values of sample_rate and duration to alleviate this problem?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **3.3. What would you say is a general rule of sampling when you need to recover both very high and very low frequencies?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [0.25, 2]\n",
    "amplitudes = [0.5, 1]\n",
    "phases = [0, 0]\n",
    "\n",
    "sample_rate = 5\n",
    "duration = 4\n",
    "\n",
    "signal_values = generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration)\n",
    "coeffs = calculate_fourier_coeffcients(signal_values, sample_rate=sample_rate, v=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "### Exercise 4 - Mathematical properties of the fourier transform\n",
    "\n",
    "Two of the most touted properties of the fourier transform are arguably:\n",
    "\n",
    "1. It is linear, meaning $F(aX + bY) =  a\\cdot F(X) + b \\cdot F(Y)$\n",
    "   1. This means, adding the scaled versions of signals in the time domain, equates to adding the scaled versions of their frequencies in the frequency domain\n",
    "2. Convolutions in the time domain are multiplications in the frequency domain and vice versa, often written as  $f(x) * h(k) = F(X) \\cdot H(X)$\n",
    "   1. You need not know what this means specifically, but we will use it more next week\n",
    "\n",
    "\n",
    "#### **ðŸ’» 4.1. Show this condition of linearity by plotting what happens in the frequency domain when you add two scaled sine waves together. You can expand the cell below as a 'skeleton' for your code, or you can code it from scratch yourself**\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set duration of signal\n",
    "duraion = ...\n",
    "\n",
    "# Set sample rate\n",
    "sample_rate = ...\n",
    "\n",
    "# Create time values for signal\n",
    "t = ...\n",
    "\n",
    "\n",
    "# Define signals...\n",
    "frequency_1 = 1\n",
    "sine_wave_1 = ...\n",
    "\n",
    "frequency_2 = 2\n",
    "sine_wave_2 = ...\n",
    "\n",
    "# Create linear combination of signals\n",
    "a = 2\n",
    "b = 4\n",
    "signal_values = ...\n",
    "\n",
    "# Get coefficients using previous fourier coefficients function\n",
    "coeffs = ...\n",
    "\n",
    "\n",
    "# Plot signal in time and frequency domain\n",
    "plt.plot(t,signal_values)\n",
    "plt.show()\n",
    "\n",
    "plt.stem(coeffs[:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 5 - Fourier transforms using packages \n",
    "\n",
    "As ML enthusiasts, we obviously never implement ourselves what the plebs have already done for us. In this case, scipy already has a rather good FFT implementation\n",
    "\n",
    "Using the FFT functions from scipy isn't actually **that** simple\n",
    "\n",
    "#### **ðŸ’» 5.1. Complete the sk_fourier_transform function to get the fourier coefficients (yf) and the fourier frequency bins (xf) from a given time signal. If you're having trouble, be sure to look up documentation or examples online for this. Test your implementation using the cell below.**\n",
    "\n",
    "#### **ðŸ’» 5.2. Change the plot_audio_signal function to only plot the positive frequencies, and get the wholly correct value of the amplitudes.**\n",
    "\n",
    "#### **ðŸ’» 5.3. Test the implementation in cases where there are frequencies that do not fit into frequency bins, and in cases were aliasing is present. How does the fourier spectrum look.**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_fourier_transform(time_signal, duration, sample_rate):\n",
    "    \"\"\"\n",
    "    Use scipy to calculate the fft of a time signal\n",
    "    \"\"\"\n",
    "    \n",
    "    # Frequency domain (FFT)\n",
    "    N = ...\n",
    "    yf = ... # Fourier coefficients\n",
    "    xf = ... # Frequency values for the for the fourier coefficient bins\n",
    "    \n",
    "    # Get the timesteps that the signal exists over (just used for convenience, not needed for the FFT)\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "\n",
    "    return xf, yf, t\n",
    "\n",
    "\n",
    "def plot_audio_signal(t, signal_time, signal_freq, signal_freq_bins, duration=None):\n",
    "    \"\"\"\n",
    "    Plot a sine wave generated as as um of given frequencies, amplitudes and phases for a given duration with a givne sample rate\n",
    "\n",
    "    Args:\n",
    "        Same as play_sine_wave, lmao\n",
    "        If duration is none, will automatically figure out duration from max frequency so you can actually see the frequencies\n",
    "        This might lead to *some* aliasing in the plots themselves\n",
    "    \"\"\"\n",
    "    # Create duration of signal if not already there\n",
    "    if not duration:\n",
    "        duration = 100 / max(frequencies)\n",
    "\n",
    "    N = len(signal_time)\n",
    "    \n",
    "    # idx = np.arange(N // 2) # Complete to only take positive part of spectrum\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Time domain plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(t, signal_time)\n",
    "    plt.title(\"Audio signal in time domain\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot frequency domain\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.stem(signal_freq_bins, (1.0 / N * np.abs(signal_freq)))  # Normalized magnitude\n",
    "    plt.title(\"Audio signal in frequency domain\")\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [50, 100, 0.0005, 880, 7000]\n",
    "amplitudes = [0.5, 1, 10, 5, 8]\n",
    "phases = [0, 0, 0, 0, 0] \n",
    "\n",
    "sample_rate = 2500\n",
    "duration = 4\n",
    "\n",
    "time_signal = generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration)\n",
    "\n",
    "xf, yf, t = sk_fourier_transform(time_signal, duration, sample_rate, positive_spectrum_only=True)\n",
    "\n",
    "plot_audio_signal(t, time_signal, yf, xf, duration=duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 6 - Noisy Signals\n",
    "\n",
    "In real life, we never have noise-free observations, so it is useful to see how noise affects our final signal as well as the fourier spectrum. The below code introduces normal distributed noise to a given signal with the following, common model:\n",
    "\n",
    "$$y(n) = s_n + \\eta_n  \\text{ }|\\text{ }  \\eta_n \\sim \\mathcal{N}(0, \\sigma)$$\n",
    "\n",
    "*Where $s_n$ is our signal of interest, $\\eta_n$ is the system noise and $y(n)$ is our observed signal*\n",
    "\n",
    "#### **ðŸ’» 6.1. Complete the function `create_noised_signal` to add noise to the observed time signal**\n",
    "\n",
    "#### **6.2. How does the fourier spectrum change when noise is introduced? How are the noise 'frequencies' expressed. Why do you think this is the case?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **6.3. Say you got an observed signal with noise as shown below, how could you approach removing the noise to only get the input frequencies out?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **6.4 Keeping in mind your idea for removing noise, how would increasing the variance of the noise impact this? Try increasing the variance of the noise and see what happens to the \"noise frequencies\" and the actual frequencies in the fourier spectrum**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **ðŸ’» 6.5 Try changing the mean value of the noise from 0 to add a so called \"DC component\". What do you think this represents? How is it reflected in the fourier spectrum?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noised_signal(time_signal, noise_mean, noise_var):\n",
    "\n",
    "    # Create random noise and add it to the time signal...\n",
    "    NotImplementedError(\"Complete this function to add random noise to a time signal\")\n",
    "\n",
    "    return noised_signal\n",
    "\n",
    "frequencies = [0.5, 2, 5]\n",
    "amplitudes = [0.5, 1, 2]\n",
    "phases = [0, 0, 0] \n",
    "\n",
    "sample_rate = 50\n",
    "duration = 4\n",
    "\n",
    "time_signal = generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration)\n",
    "noised_signal = create_noised_signal(time_signal, noise_mean=0, noise_var=4)\n",
    "\n",
    "xf, yf, t = sk_fourier_transform(noised_signal, duration, sample_rate)\n",
    "\n",
    "plot_audio_signal(t, noised_signal, yf, xf, duration=duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "### Exercise 7 - Looking at noised signals\n",
    "\n",
    "Another really useful property of the fourier transform, is that we as humans just cannot get much information from the time spectrum in general. Below is code to plot two different noised signals in the time and frequency domain.\n",
    "\n",
    "#### **7.1. Consider the two noised signals below. Here the exercise is mostly to realize the importance of the frequency domain, especially in tasks that require pinpointing specific frequencies in signals. In the time domain, the signals look almost identical, in the frequency domain, there is a huge and obvious difference.**\n",
    "\n",
    "**You will see this be useful again next week during assignment 2 when you need to classify brain waves based on their frequency content.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_signal_1 = [0.5, 2, 5]\n",
    "amplitudes_signal_1 = [0.5, 1, 2]\n",
    "\n",
    "frequencies_signal_2 = [20]\n",
    "amplitudes_signal_2 = [5]\n",
    "\n",
    "phases = [0, 0, 0] \n",
    "\n",
    "sample_rate = 50\n",
    "duration = 4\n",
    "\n",
    "time_signal_1 = generate_sine_wave(amplitudes_signal_1, frequencies_signal_1, phases, sample_rate, duration)\n",
    "time_signal_2 = generate_sine_wave(amplitudes_signal_2, frequencies_signal_2, phases, sample_rate, duration)\n",
    "\n",
    "mean = 0 # Change this to introduce a 'dc component' to the noise\n",
    "variance = 4 # Change this to increase the prescence of the noise\n",
    "\n",
    "noised_signal_1 = create_noised_signal(time_signal_1, mean, variance)\n",
    "noised_signal_2 = create_noised_signal(time_signal_2, mean, variance)\n",
    "\n",
    "xf_1, yf_1, t = sk_fourier_transform(noised_signal_1, duration, sample_rate)\n",
    "plot_audio_signal(t, noised_signal_1, yf_1, xf_1, duration=duration)\n",
    "\n",
    "xf_2, yf_2, t = sk_fourier_transform(noised_signal_2, duration, sample_rate)\n",
    "plot_audio_signal(t, noised_signal_2, yf_2, xf_2, duration=duration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "### Exercise 8 - Human speech and noise\n",
    "\n",
    "As previously mentioned, most of human speech is typically around the 90 - 3500 Hz range. It can be interesting to look at actual voice signals to see how they behave. The cell below loads one of four voice signals spelling out \"S O F A\"\n",
    "\n",
    "We redefine fourier transform and plotting functions to work with loaded data\n",
    "\n",
    "1. A clean signal where only the speech is presen\n",
    "2. A signal where white noise has been added in the background\n",
    "3. A signal where non-white noise in the form of a fan has been added\n",
    "4. A signal where non-white noise in the form of human speech has been added\n",
    "\n",
    "#### **8.1. ðŸ’» Load the clean signal and see if you can recognize the difference between consonants and vowels in the time domain, what about the frequency domain?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **8.2. ðŸ’» Load the two different noised signals. How do the different types of noise stand out from one another?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **8.3. ðŸ’» Play with the function mix_noise to mix different types of noise with the clean signal. What combinations of noise make the clean signal the most unintelligeble from an audio standpoint?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **8.4 What combinations of noise make the clean signal the most unintelligeble when looking at just the plot of the time and frequency domain**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **8.5. In general, what types of the presented noise do you think are the most difficult to remove out when the clean signal is human speech?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine fourier transform and plot functions because they don't really work when we have signals with set durations\n",
    "def sk_fourier_transform(time_signal, t, sample_rate):\n",
    "    \"\"\"\n",
    "    Use scipy to calculate the fft of a time signal\n",
    "    \"\"\"\n",
    "    # Get the timesteps that the signal exists over\n",
    "    t = np.linspace(0, time_signal.size / sample_rate, time_signal.size, endpoint=False)\n",
    "    \n",
    "    # Frequency domain (FFT)\n",
    "    N = len(time_signal)\n",
    "    yf = fft(time_signal) # Fourier coefficients\n",
    "    xf = fftfreq(N, 1 / sample_rate) # Frequency values for the for the fourier coefficient bins\n",
    "    \n",
    "    return xf, yf, t\n",
    "\n",
    "\n",
    "def plot_audio_signal(t, signal_time, signal_freq, signal_freq_bins, duration=None, max_freq=5000):\n",
    "    \"\"\"\n",
    "    Plot a sine wave generated as as um of given frequencies, amplitudes and phases for a given duration with a givne sample rate\n",
    "\n",
    "    Args:\n",
    "        Same as play_sine_wave, lmao\n",
    "        If duration is none, will automatically figure out duration from max frequency so you can actually see the frequencies\n",
    "        This might lead to *some* aliasing in the plots themselves\n",
    "    \"\"\"\n",
    "    # Create duration of signal if not already there\n",
    "    if not duration:\n",
    "        duration = 100 / max(frequencies)\n",
    "\n",
    "    N = len(signal_time)\n",
    "    \n",
    "    idx = np.arange(N // 2) # Complete to only take positive part of spectrum\n",
    "\n",
    "    if max_freq is not None and max_freq > 0:\n",
    "        idx = idx[:max_freq]\n",
    "\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Time domain plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(t, signal_time)\n",
    "    plt.title(\"Audio signal in time domain\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot frequency domain\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(signal_freq_bins[idx], (2.0 / N * np.abs(signal_freq[idx])))  # Normalized magnitude\n",
    "    plt.title(\"Audio signal in frequency domain\")\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofa_path = \"audio/sofa.wav\"\n",
    "fan_noise_path = \"noise_examples/fan_noise.wav\"\n",
    "talking_path = \"noise_examples/talking.wav\"\n",
    "\n",
    "sample_rate, time_signal = read(sofa_path)\n",
    "time_signal = 5 * np.array(time_signal[1:, 0],dtype=float)   # Indexed to make N odd\n",
    "\n",
    "\n",
    "def mix_noise(observed_signal, noise_paths, noise_amplitudes, white_noise_variance=10, whtie_noise_mean=0, white_noise_amplitude=10):\n",
    "    \"\"\"\n",
    "    Load and mix different white noise sources\n",
    "    \"\"\"\n",
    "    for noise_path, noise_amplitude in zip(noise_paths, noise_amplitudes):\n",
    "        print(noise_path)\n",
    "        _, noise_signal = read(noise_path)\n",
    "        noise_signal = np.array(noise_signal[1:, 0],dtype=float)[: len(observed_signal-1)]\n",
    "        observed_signal += noise_signal * noise_amplitude\n",
    "\n",
    "    # Create and add white noise\n",
    "    white_noise = np.random.normal(loc=whtie_noise_mean, scale=white_noise_variance, size=len(time_signal))\n",
    "    observed_signal += white_noise_amplitude * white_noise\n",
    "\n",
    "    return observed_signal\n",
    "\n",
    "\n",
    "print(f\"Sample rate is: {sample_rate}Hz\")\n",
    "\n",
    "time_signal = mix_noise(time_signal, [fan_noise_path, talking_path], [0.05, 0.05])\n",
    "\n",
    "# Create fourier transform, plot signal\n",
    "xf, yf, t = sk_fourier_transform(time_signal, duration, sample_rate)\n",
    "plot_audio_signal(t, time_signal, yf, xf, duration=duration, max_freq=5000)\n",
    "Audio(time_signal,rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #00695C; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "## Part 2 - Exercises on filtering\n",
    "\n",
    "These are exercises you haven't seen before\n",
    "\n",
    "As mentioned, after these will be optional exercises for this, and last week\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Catch up: Filtering\n",
    "\n",
    "As mentioned, filtering is rather easy enough, we are going to focus on just convolution, plotting filters and using filters in time and frequency domain. As a reminder, the formula for signal convolution is\n",
    "\n",
    "$$y(k) = x(n) * h(n) = \\sum^{\\infty}_{n=-\\infty} x(n) h(k - n)$$\n",
    "\n",
    "### High-, low, and band-pass filtering\n",
    "\n",
    "The most commonly used filters, are usually some variant of high-pass filters, low-pass filters and band-pass filters. They work in the following ways:\n",
    "\n",
    "- **High-pass**: Let the high frequencies pass, meaning the result is a signal with only high frequencies\n",
    "- **Low-pass**: Let the low frequencies pass, meaning the signal will only have low frequencies\n",
    "- **Band-pass**: Let frequencies in a specific band (for example 400 to 800 Hz) pass, meaning the signal will only have those frequencies\n",
    "\n",
    "If we look at how these filters look in the **frequency domain**, it is roughly equal to this:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/actual_filters.png\" alt=\"\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "Ignore the band-stop filter, it is not important for our purposes. \n",
    "\n",
    "**Remember**, these are in the frequency domain, so the x-axis will show *what* frequencies will be affected, and the y-axis will show how those frequencies will be affected by the filter. \n",
    "\n",
    "So, if $h$ is our filter, $h(5) = 10$, for example, means that the amplitude of the frequency $5$ in our signal, will be multiplied by $10$ after applying the filter $h$\n",
    "\n",
    "\n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 9 - Filtering in Python\n",
    "\n",
    "*We meant to have an exercise centered around implementing your own convolution function to use a pre-made filter to do low-pass filtering... However that was prohibitively overcomplicated. Take that as a lesson, that if someone else has done it, it is probably better than what you can make yourself*\n",
    "\n",
    "*That said, we still wanna 'get' filtering. Both manually and using packages. Below the functions butter_lowpass and butter_lospass_filter create a so-called [butterworth](https://en.wikipedia.org/wiki/Butterworth_filter) filter and apply it to a signal respectively.*\n",
    "\n",
    "In the two cells below: We've implemented a function to make, and apply a \"butterworth filter\". Which is essentially \"the closest we can get to low-pass, high-pass, or band-pass filters, IRL\". We wanna look at the output of the code.\n",
    "\n",
    "#### **9.1. Inspect the plots created by running the code two cells below. What are the visibile effects on time and frequency domain?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **9.2. ðŸ’» Change the value of the frequency_cutoff, how does this change the plots and the resulting audio?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **9.3. The Butterworth filter is described as a 'maximally flat magnitude filter' what do you think this refers to. Why can we in actuality not just construct a completely flat filter?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    \"\"\"\n",
    "    Create a butterworth lowpass filter, given a cutoff frequency and sampling rate\n",
    "    \"\"\"\n",
    "    # Nyquist rate\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    \n",
    "    # Use scipy to get butter filter\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    \"\"\"\n",
    "    Create and apply a butterworth lowpass filter to a signal\n",
    "    \"\"\"\n",
    "    # Create lowpass filter using afforementioned function\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    # Apply filter using filtfilt function\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sofa example, same as before\n",
    "sofa_path = \"audio/sofa.wav\"\n",
    "sample_rate, time_signal = read(sofa_path)\n",
    "time_signal = np.array(time_signal[1:, 0],dtype=float)\n",
    "\n",
    "# Filter time signal using butter lowpass filter, only let frequencies of frequency_cutoff pass\n",
    "frequency_cutoff = 1000\n",
    "filtered_signal = butter_lowpass_filter(time_signal, 1000, fs=sample_rate, order= 5)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12,10))\n",
    "\n",
    "# Plot the original signal in the time domain\n",
    "axs[0, 0].plot(np.arange(len(time_signal)), time_signal)\n",
    "axs[0, 0].set_title('Original Signal, time domain')\n",
    "axs[0, 0].set_xlabel('Time')\n",
    "axs[0, 0].set_ylabel('Magnitude')\n",
    "\n",
    "# Plot the filtered signal in the time domain\n",
    "axs[0, 1].plot(np.arange(len(filtered_signal)), filtered_signal)\n",
    "axs[0, 1].set_title('Filtered Signal, time domain')\n",
    "axs[0, 1].set_xlabel('Time')\n",
    "axs[0, 1].set_ylabel('Magnitude')\n",
    "\n",
    "# Obtain freqeuncy domain\n",
    "xf = fftfreq(len(time_signal), 1 / sample_rate)\n",
    "yf_original = np.abs(fft(time_signal))\n",
    "yf_filtered = np.abs(fft(filtered_signal))\n",
    "\n",
    "# Plot the original signal in the frequency domain\n",
    "axs[1, 0].plot(xf, yf_original)\n",
    "axs[1, 0].set_title('Original signal, frequency domain')\n",
    "axs[1, 0].set_xlabel('Frequency')\n",
    "axs[1, 0].set_ylabel('Magnitude')\n",
    "\n",
    "# Plot the filtered signal in the frequency domain\n",
    "axs[1, 1].plot(xf, yf_filtered)\n",
    "axs[1, 1].set_title('Filtered signal, frequency domain')\n",
    "axs[1, 1].set_xlabel('Frequency')\n",
    "axs[1, 1].set_ylabel('Magnitude')\n",
    "\n",
    "\n",
    "Audio(filtered_signal, rate = sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 10 - Manual filter calculations\n",
    "\n",
    "*It is good thing to try at least one manual calculation of convolution with a filter, as terrible as it may sound...*\n",
    "\n",
    "#### **10.1. Given the below values:**\n",
    "\n",
    "$$x_n = \\begin{cases} \n",
    "        \\frac{1}{2} n  & \\text{for} 0 \\leq n \\leq 6 \\\\\n",
    "        0 & \\text{elsewhere}\n",
    "        \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "$$h_n = \\begin{cases} \n",
    "        1  & \\text{for} -2 \\leq n \\leq 2 \\\\\n",
    "        0 & \\text{elsewhere}\n",
    "        \\end{cases}\n",
    "$$\n",
    "\n",
    "#### **Calculate $y(k)$ as a of the convolution $x(k) * h(k)$ for $k = -1$, $k = 4$ and $k = 7$**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "### Exercise 11 - Fliter implementation\n",
    "\n",
    "*Below we implement filtering manually, which can be scary. We do this in two ways: One is simply multiplying the values in the frequency spectrum. The other is using the filter from the aforementioned method to convolve the signal in time domain. This avoids the somewhat more stringent math of creating filters in the time domain.*\n",
    "\n",
    "#### **11.1. ðŸ’» (Challenging) Complete the code to perform filtering in the frequency domain** \n",
    "\n",
    "HINT: If you're just a tiny bit stuck on this, don't worry, it is kind of an experiment to see if writing more code from scratch would be better. If you get stuck, just checkout the solution and take it from there...\n",
    "\n",
    "#### **11.2. Inspect the plots of the filtering code. Determine what kind of filter it is by looking at its impulse response, as well as the fourier spectrum of the filtered signal. Beware of the options `positive_freqs_only` and `human_speech_cutoff`, which will restrict the plot to only positive frequencies, and only human frequencies respectively**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **11.3 ðŸ’». Change the type of the filter by changing the cutoff_freq parameter. Try to make a high-pass filter and a band-pass filter. Listen to the resulting audio from both these**\n",
    "\n",
    "\n",
    "####  (OPTIONAL): **$\\star \\star$ 11.4. As mentioned, we can also filter in the time domain. Do so using the apply_convolution function and answer the following questions:**\n",
    "\n",
    "1. **What do we use the IFFT for?**\n",
    "2. **Why do we use np.roll?**\n",
    "3. **What is the result of doing the convolution, compared to filtering in the frequency domain?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_domain_filtering(time_signal : np.ndarray, sample_rate : int, cutoff_freq : list):\n",
    "    \"\"\"\n",
    "    Filter a signal by multiplying its fourier transform with specific values\n",
    "    Args:\n",
    "        time_signal (np.ndarray): input time-domain signal\n",
    "        sample_rate (int): sampling rate of the signal\n",
    "        cutoff_freq (list): list of [low_cutoff, high_cutoff] frequencies. If either set to 0, we assume low or high pass filtering for that particular frequency\n",
    "    \"\"\"\n",
    "\n",
    "    # You wanna:\n",
    "    # Get the frequency bins using our number of samples, sample rate (in hz) and the fftfreq function\n",
    "    # get the index of the frequency bins that corresponds to our cutoff frequency, both high and low\n",
    "    # Create a frequency mask that equals all frequencies in our frequency bins\n",
    "    # Take all values that are contained within the range of lowpass_index to highpass_index and set them to 1\n",
    "    # Set every other frequency to zero (easy if the frequency mask was made using np.zeros)\n",
    "    # get the filtered signal by applying the fft to our time signal\n",
    "    # apply the frequency mask to our filtered signal\n",
    "    # get filtered time signal by using the inverse fast fourier transform (np.fft.ifft)\n",
    "    # get the real (non imaginary) parts of this numpy array\n",
    "    # profit\n",
    "\n",
    "    # BUNCH OF CODE GOES HERE!\n",
    "    ...\n",
    "\n",
    "\n",
    "    return filtered_signal, frequency_mask, xf, yf\n",
    "\n",
    "def apply_convolution(time_signal: np.ndarray, frequency_mask: np.ndarray):\n",
    "    \"\"\"\n",
    "    Apply convolution using a filter kernel obtained from inverse FFT of the frequency mask.\n",
    "    Args:\n",
    "        time_signal (np.ndarray): Original time-domain signal.\n",
    "        frequency_mask (np.ndarray): Frequency mask used in the filtering process.\n",
    "    Returns:\n",
    "        convolved_signal (np.ndarray): Signal after applying convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtain the filter kernel by inverse Fourier transform of the frequency mask\n",
    "    filter_kernel = np.real(ifft(frequency_mask))\n",
    "    \n",
    "    # Shift kernel to be centered (necessary since the kernel is symmetric)\n",
    "    filter_kernel = np.roll(filter_kernel, len(filter_kernel) // 2)\n",
    "\n",
    "    # Perform convolution with the time signal (if using convolution methods, don't use your own, use scipy's (it's faster))\n",
    "    convolved_signal = convolve(time_signal, filter_kernel, mode='same')\n",
    "\n",
    "    return convolved_signal, filter_kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio same as before...\n",
    "sofa_path = \"audio/sofa.wav\"\n",
    "sample_rate, time_signal = read(sofa_path)\n",
    "time_signal = np.array(time_signal[1:, 0],dtype=float)\n",
    "\n",
    "# Decide whether you want the full or the partial plot\n",
    "positive_freqs_only = False\n",
    "\n",
    "# Decide whether we are only interested in the frequencies likely to be associated with human speech\n",
    "human_speech_cutoff = False\n",
    "\n",
    "if human_speech_cutoff and not positive_freqs_only:\n",
    "    print(\"Warning: Cannot plot only human frequencies, if you do not cut off positive frequencies first...\")\n",
    "    print(\"I mean, you can, but it hasn't been implmeneted here...\")\n",
    "\n",
    "# Filter the signal in frequency domain\n",
    "# filtered_signal, frequency_mask = frequency_domain_filtering(time_signal, sample_rate, cutoff_freq=[0, 380])\n",
    "filtered_signal, frequency_mask, xf, _ = frequency_domain_filtering(time_signal, sample_rate, cutoff_freq=[0, 380])\n",
    "\n",
    "# Filter signal in time domain using convolution\n",
    "convolved_signal, time_filter = apply_convolution(time_signal, frequency_mask)\n",
    "\n",
    "# Obtain the FFT of the original and filtered signals respectively\n",
    "original_freq_domain = np.abs(fft(time_signal))\n",
    "filtered_freq_domain = np.abs(fft(filtered_signal))\n",
    "\n",
    "############## PLOTTING ##############\n",
    "\n",
    "# Create a 3x2 subplot layout\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 15))\n",
    "\n",
    "# If we have requested to not have the positive frequencies at all...\n",
    "if positive_freqs_only:\n",
    "    xf_pos = xf[:len(time_signal) // 2]\n",
    "\n",
    "    xs = xf_pos\n",
    "    ys = frequency_mask[:len(xs)]\n",
    "    \n",
    "    # Furthermore, if we have requested to only get frequencies, likely to be in the human vocal range...\n",
    "    if human_speech_cutoff:\n",
    "        speech_mask = (xs >= 0) & (xs <= 8000)\n",
    "        xs = xs[speech_mask]\n",
    "        ys = ys[speech_mask]\n",
    "\n",
    "# Else, we'll just get all, positive and negative frequencies\n",
    "else:\n",
    "    xs = np.arange(len(frequency_mask))\n",
    "    xs = xf\n",
    "    ys = frequency_mask\n",
    "\n",
    "\n",
    "# Plot the filter kernel in frequency domain\n",
    "axs[0, 0].plot(xs, ys)\n",
    "axs[0, 0].set_title('Created (bandpass) filter in Fourier spectrum')\n",
    "axs[0, 0].set_xlabel('Frequency (hz)')\n",
    "axs[0, 0].set_ylabel('Magnitude')\n",
    "\n",
    "# Plot filter in time domain\n",
    "# Get 300 steps away from the center on both sides of the filter\n",
    "center = len(time_filter) // 2\n",
    "time_filter_limited = time_filter[center - 300 : center + 300]\n",
    "\n",
    "axs[1, 0].plot(np.arange(len(time_filter_limited)), time_filter_limited)\n",
    "axs[1, 0].set_title('Created filter in time domain')\n",
    "axs[1, 0].set_xlabel('k')\n",
    "axs[1, 0].set_ylabel('h(k)')\n",
    "\n",
    "# Plot the original time signal\n",
    "axs[0, 1].plot(np.arange(len(time_signal)), time_signal)\n",
    "axs[0, 1].set_title('Original Time Signal')\n",
    "axs[0, 1].set_xlabel('Sample index')\n",
    "axs[0, 1].set_ylabel('Amplitude')\n",
    "\n",
    "# Plot the convolved signal\n",
    "axs[1, 1].plot(np.arange(len(filtered_signal)), filtered_signal)\n",
    "axs[1, 1].set_title('Filtered Signal')\n",
    "axs[1, 1].set_xlabel('Sample index')\n",
    "axs[1, 1].set_ylabel('Amplitude')\n",
    "\n",
    "# Same as above, but now for the signal in the time domain\n",
    "if positive_freqs_only:\n",
    "    xf_pos = xf[:len(time_signal) // 2]\n",
    "\n",
    "    # Get frequency bins for plotting (positive frequencies only)\n",
    "    xs = xf_pos\n",
    "    original_freq_domain = original_freq_domain[:len(xs)]\n",
    "    filtered_freq_domain = filtered_freq_domain[:len(xs)]\n",
    "\n",
    "    # Apply speech mask if needed\n",
    "    if human_speech_cutoff:\n",
    "        speech_mask = (xs >= 80) & (xs <= 8000)\n",
    "        xs = xs[speech_mask]\n",
    "        original_freq_domain = original_freq_domain[speech_mask]\n",
    "        filtered_freq_domain = filtered_freq_domain[speech_mask]\n",
    "else:\n",
    "    xs = np.arange(len(original_freq_domain))\n",
    "    xs = xf\n",
    "    # original_xs = np.arange(len(original_freq_domain))\n",
    "    original_ys = original_freq_domain\n",
    "\n",
    "    # filtered_xs = np.arange(len(filtered_freq_domain))\n",
    "    filtered_ys = filtered_freq_domain\n",
    "\n",
    "# Plot the Fourier domain of the original signal\n",
    "axs[0, 2].plot(xs, original_freq_domain)\n",
    "axs[0, 2].set_title('Fourier spectrum of Original Signal')\n",
    "axs[0, 2].set_xlabel('Frequency (hz)')\n",
    "axs[0, 2].set_ylabel('Magnitude')\n",
    "\n",
    "# Plot the Fourier domain of the filtered signal\n",
    "axs[1, 2].plot(xs, filtered_freq_domain)\n",
    "axs[1, 2].set_title('Fourier spectrum of Filtered Signal')\n",
    "axs[1, 2].set_xlabel('Frequency (hz)')\n",
    "axs[1, 2].set_ylabel('Magnitude')\n",
    "\n",
    "\n",
    "# Display the audio created\n",
    "Audio(filtered_signal, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #00695C; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Optional Exercises starts\n",
    "\n",
    "As mentioned, these are just some of the optional exercises from this and last time...\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "### $\\star$ Exercise 12 - The Short-Time Fourier transform\n",
    "\n",
    "This is just to show what can also be done. There is something called the short time fourier transform (STFT). What this does is split a time signal into a bunch of smaller time intervals, and computes the fourier transform for each smaller interval. Laying all of these FT's in series produces what is known as a spectogram, which you may have already know from Intro to Intelligent systems\n",
    "\n",
    "#### **12.1 Why would you do this?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **12.2. How do you implement this?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## MATPLOTLIB AND NUMPY IMPLEMENTATION - LESS 'BLACK BOXY' ##############\n",
    "############## BUT GIVES *SHIT* SPECTROGRAMS! ##############\n",
    "# def plot_stft(time_signal, sample_rate, max_freq=10000,\n",
    "#                 smooth=True, convert_to_db=True, \n",
    "#                 threshold=75, title=None):\n",
    "    \n",
    "#     # Perform STFT\n",
    "#     f, t, Zxx = stft(time_signal, fs=sample_rate, nperseg=1024,  window='hamming')\n",
    "\n",
    "#     # Filter out the frequencies above the desired range\n",
    "#     freq_mask = f <= max_freq\n",
    "#     f_filtered = f[freq_mask]\n",
    "#     Zxx_filtered = Zxx[freq_mask, :]\n",
    "\n",
    "#     Zxx_magnitude = np.abs(Zxx_filtered)\n",
    "    \n",
    "#     if threshold: # If trehsold is set, remove all values below the (to reinforce the most important parts of the signal)\n",
    "#         threshold = np.percentile(Zxx_magnitude, 75)\n",
    "#         Zxx_magnitude[Zxx_magnitude < threshold] = 0\n",
    "    \n",
    "#     if convert_to_db:\n",
    "#         Zxx_magnitude_db = 20 * np.log10(Zxx_magnitude + 1e-10)  # Add a small epsilon to avoid log(0)\n",
    "        \n",
    "#     else:\n",
    "#         Zxx_magnitude_db = Zxx_magnitude\n",
    "\n",
    "#     if smooth: # Smoothing to make the plot more visually appealing\n",
    "#         from scipy.ndimage import gaussian_filter\n",
    "#         Zxx_magnitude_db = gaussian_filter(Zxx_magnitude_db, sigma=0.5)\n",
    "\n",
    "#     # Plot the spectrogram, here we use pcolormesh, since there is tehnically like three axes\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.pcolormesh(t, f_filtered, Zxx_magnitude_db, shading='gouraud')\n",
    "#     if not title:\n",
    "#         plt.title('Spectrogram of the Audio Signal')\n",
    "#     else:\n",
    "#         plt.title(title)\n",
    "#     plt.ylabel('Frequency [Hz]')\n",
    "#     plt.xlabel('Time [sec]')\n",
    "#     plt.colorbar(label='Magnitude (dB)')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    # return time_signal, sample_rate\n",
    "\n",
    "\n",
    "# def load_file_and_plot_stft(file_path, start_duration=None, **kwargs):  \n",
    "#     \"\"\"\n",
    "#     Just a convenience function to load a file *and* plot the stft of it\n",
    "#     \"\"\"\n",
    "#     sample_rate, time_signal = read(file_path)\n",
    "\n",
    "#     if start_duration:\n",
    "#         time_signal = time_signal[start_duration[0]*sample_rate: start_duration[0]*sample_rate +  start_duration[1]*sample_rate]\n",
    "\n",
    "#     # Pre-process time signal\n",
    "#     time_signal = np.array(time_signal[1:, 0], dtype=float)  # Indexed to make N odd\n",
    "\n",
    "\n",
    "#     time_signal, sample_rate = plot_stft(time_signal, sample_rate, **kwargs)\n",
    "#     return time_signal, sample_rate\n",
    "\n",
    "# _ = load_file_and_plot_stft('audio/sofa.wav', title='Spectogram S O F A example')\n",
    "\n",
    "# sample_rate, time_signal = read('R060_004.wav')\n",
    "# time_signal = np.array(time_signal[1:, 0], dtype=float)  # Indexed to make N odd\n",
    "\n",
    "\n",
    "######### LIBROSA IMPLEMENTATION - MUCH BETTER SPECTROGRAMS, MORE 'BLACK BOXY' #########\n",
    "def plot_stft(time_signal, sample_rate,\n",
    "                mel=True, title=None, **kwargs):\n",
    "\n",
    "    # Compute spectrogram - Use mel spectogram to better capture frequencies of note\n",
    "    if mel:\n",
    "        spec = librosa.feature.melspectrogram(y=time_signal, sr=sample_rate)\n",
    "    else:\n",
    "        spec = np.abs(librosa.stft(y=time_signal)) ** 2\n",
    "    # Convert power to decibels\n",
    "    spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "    # Plot spectrogram\n",
    "    # fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    img = librosa.display.specshow(spec_db, x_axis='time', y_axis='mel')\n",
    "    # plt.colorbar(img, ax = ax, format='%+2.0f dB')\n",
    "    plt.colorbar(img, format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return time_signal, sample_rate\n",
    "\n",
    "def load_file_and_plot_stft(file_path, existing_time_signal=None, start_duration=[0, None], **kwargs):\n",
    "    # Load audio file\n",
    "    time_signal, sample_rate = librosa.load(file_path, offset=start_duration[0], duration=start_duration[1], mono=True)\n",
    "\n",
    "    # If we add an already-existing time_signal, just use it, useful for if we wanna show filtering.\n",
    "    if existing_time_signal is not None:\n",
    "        time_signal = existing_time_signal\n",
    "\n",
    "    plot_stft(time_signal, sample_rate, **kwargs)\n",
    "    return time_signal, sample_rate\n",
    "\n",
    "time_signal, sample_rate = load_file_and_plot_stft('audio/sofa.wav', title=\"Sofa\")\n",
    "\n",
    "Audio(time_signal,rate = sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "**Having such a \"clean\" audio where there is almost no sound in many places is a big boring to look at, having for example a music clip might be more interesting...**\n",
    "\n",
    "**Here is where the exercises end. If you want, I've collected a bunch of different examples of sound in the extra_spectograms folder that I think would be interesting to see both the spectogram of, if not also the fourier transform and the time domain signal. You can plot them using the below code if you want**\n",
    "\n",
    "**Note, you can change the 'max_freq' if you want to see higher frequencies or want greater resolution on the lower frequencies.**\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import titles\n",
    "\n",
    "print(\"INFO: Remember to uncomment bottom filtering code if you wanna listen to or watch the filtered example\")\n",
    "\n",
    "# Typical examples of young-people music\n",
    "time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/good_music.wav\", start_duration=[30, 15], title=titles.all_titles[0])\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/hutcher.wav\", title=titles.all_titles[1])\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/broken.wav\", title=titles.all_titles[2])\n",
    "\n",
    "# A bass singer (low pitch)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/bass_singer.wav\", title=titles.all_titles[3])\n",
    "\n",
    "# A tenor singer (high pitch)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/tenor_singer.wav\", title=titles.all_titles[4])\n",
    "\n",
    "# A guitar solo (medium pitch)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/guitar_solo.wav\", title=titles.all_titles[5])\n",
    "\n",
    "# A bass solo (low pitch)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/bass_solo.wav\", title=titles.all_titles[6])\n",
    "# A songbird (perhaps distortion)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/songbird.wav\", title=titles.all_titles[7])\n",
    "\n",
    "# A human songbird (????)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/human_songbird.wav\", title=titles.all_titles[8])\n",
    "\n",
    "# A bunch of people talking at the same time\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/people_talking.wav\", title=titles.all_titles[9])\n",
    "\n",
    "\n",
    "\n",
    "# # Optionally apply some filtering here\n",
    "# cutoff_frequencies = [2000, 4000] # Initially, bandpass\n",
    "# current_sound = \"extra_spectograms/bass_singer.wav\"\n",
    "# time_signal, frequency_mask, _, _ = frequency_domain_filtering(time_signal, sample_rate, cutoff_freq=[2000, 4000])\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(current_sound, existing_time_signal=time_signal, title=titles.all_titles[3] + \" (Filtered)\")\n",
    "\n",
    "# If you want to play the audio\n",
    "Audio(time_signal,rate = sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### $\\star$ Exercise 13 - proving the fourier transform is linear\n",
    "\n",
    "In exercise 4, we gave some examples that emperically \"showed\" that the fourier transform was linear.\n",
    "\n",
    "### **13.1. Mathematically prove that the fourier transform (discrete case) is linear**\n",
    "\n",
    "*Hint: Look at two different functions x and y, not different values of k*\n",
    "\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "### $\\star$ Exercise 14 - The \"power\" of noise\n",
    "\n",
    "#### **14.1 The variance of the noise is often referred to as the \"power\" of the noise, why do you supose this is?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "### $\\star$ Exercise 15 - Alice, Charlie and Bob's noise\n",
    "\n",
    "Noise is present everywhere, but can be circumvented in quite a few cases. The following questions are mostly discussion and reflection questions, there may not be a 'true answer'\n",
    "\n",
    "### **Case 15.1:**\n",
    "- **Alice uses her phone to call Bob.**\n",
    "- **Alice's phone signal occupies the frequency range 600MHz to 1GHz (somewhat normal for phones).**\n",
    "- **Charlie is right next to Alice during her call, and is watching a Joe Rogan podcast using Wifi, which he recieves on the frequency band 2.4GHz to 5GHz.**\n",
    "\n",
    "#### **15.1.1 Is the call between Alice and Bob in danger of being cut off? Why/Why not?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "#### **15.1.2 Say Charlie *wants* to mess with Alice and Bob by interrupting their call. How could he go about this?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **15.2. Reflect on what can cause noise in the following scenarios:**\n",
    "\n",
    "1. **Talking in a crowded room**\n",
    "2. **A phone getting wifi signal in a crowded mall**\n",
    "3. **An alien race sending a signal to earth so NASA can hear it.**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **15.3. You are an engineer working for the well-known and respected military contractor, Suckheed Fartin (Skibidi Gyattin). Recently, the military has been having issues where nasty people have used radios to send mean messages to the pilots of fighter jets flying missions, this of course makes the pilots very sad, and the military wants a solution.**\n",
    "\n",
    "**How would you, armed with your newfound knowledge of signal processing, go about solving the issue of these mean messages. For practical purposes, the pilots cannot turn off their radios or change the reciever frequencies on their radios**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signals-and-data-autumn-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
